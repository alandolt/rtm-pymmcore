{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymmcore_plus import CMMCorePlus\n",
    "from fov import FOV\n",
    "import useq\n",
    "from useq import MDAEvent\n",
    "from queue import Queue\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from napari import Viewer\n",
    "import numpy as np\n",
    "from queue import Queue\n",
    "from pymmcore_plus import CMMCorePlus\n",
    "from useq import MDAEvent\n",
    "import useq\n",
    "from useq._channel import Channel\n",
    "from MDAEngine_DMD import MDAEngine_DMD\n",
    "from controller import Controller, Analyzer\n",
    "import pandas as pd\n",
    "import random\n",
    "from utils import ImgType, MetadataDict\n",
    "from stimulation import StimExtraParameters\n",
    "from dmd import DMD\n",
    "from hardware import load_config\n",
    "import os\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "import pymmcore\n",
    "import napari\n",
    "from tracking import TrackerTrackpy\n",
    "from utils import create_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO check if dmd calibration works\n",
    "#TODO adjust napari live view, check how they change brightness in napari-umanager (or directly use napari-umanager?)\n",
    "#TODO add napari widget to store/display positions\n",
    "#TODO generate necessary folders beforehand\n",
    "#TODO add to known issues: conda install -c conda-forge llvm-openmp if there are issues with threads on M1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load uManager and set default devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmc = CMMCorePlus() #Create a new instance of the CMMCorePlus class\n",
    "mmc.loadSystemConfiguration('local/local_config.cfg')  #Load the system configuration file (standard uManager .cfg file)\n",
    "#load_config(mmc) #Set the default device from the YAML file (specific to this package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logfile: Z:\\lhinder\\data\\rtm_mm_data\\exp_355\\log.txt\n"
     ]
    }
   ],
   "source": [
    "# Create a new log file in the temp directory\n",
    "log_dir = tempfile.gettempdir()\n",
    "log_dir = 'Z:\\\\lhinder\\\\data\\\\rtm_mm_data\\\\exp_355\\\\'\n",
    "log_file = os.path.join(log_dir, \"log.txt\")\n",
    "\n",
    "# Get the current date and time\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "print(f\"Logfile: {log_file}\")\n",
    "\n",
    "# Open the log file in append mode and write the date and time\n",
    "with open(log_file, \"w\") as file: #w: write (delete old content), a: append\n",
    "    file.write(f\"{current_time}\\n\")\n",
    "    file.write(f\"User ID: {mmc.getUserId()}\")\n",
    "\n",
    "    file.write(f\"PyMMCore version {pymmcore.__version__}\\n\")\n",
    "    file.write(f\"{mmc.getAPIVersionInfo()}\")\n",
    "    file.write(f\"{mmc.getVersionInfo()}\\n\\n\")\n",
    "\n",
    "    file.write(\"Loaded devices:\\n\")\n",
    "    file.write(\"\\n\".join(str(device) for device in mmc.getLoadedDevices()))\n",
    "    file.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewer = napari.Viewer()\n",
    "#image_layer = viewer.add_image(np.ones((1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Z:\\lhinder\\data\\rtm_mm_data\\exp_355\\stim already exists\n",
      "Directory Z:\\lhinder\\data\\rtm_mm_data\\exp_355\\raw already exists\n",
      "Directory Z:\\lhinder\\data\\rtm_mm_data\\exp_355\\mask already exists\n",
      "Directory Z:\\lhinder\\data\\rtm_mm_data\\exp_355\\stim_mask already exists\n"
     ]
    }
   ],
   "source": [
    "path = log_dir\n",
    "create_folders(path,['stim','raw','mask','stim_mask'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list with FOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current position\n",
    "pos = (mmc.getXPosition(),mmc.getYPosition())\n",
    "pos_list = [pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16539.000246450305\n",
      "-12507.900186382234\n"
     ]
    }
   ],
   "source": [
    "print(mmc.getXPosition())\n",
    "print(mmc.getYPosition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16539.000246450305, -12507.900186382234)\n"
     ]
    }
   ],
   "source": [
    "#pos_list = [(2,2)]\n",
    "fovs = []\n",
    "\n",
    "for i,pos in enumerate(pos_list):\n",
    "    print(pos)\n",
    "    fov = FOV(pos=pos,\n",
    "              index =i,\n",
    "              path=path,\n",
    "              metadata={},\n",
    "              properties={'stim_property': 'top'},\n",
    "              )\n",
    "    fovs.append(fov)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DF with all planned acquisitions and stimulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fov</th>\n",
       "      <th>timestep</th>\n",
       "      <th>time</th>\n",
       "      <th>time_experiment</th>\n",
       "      <th>treatment</th>\n",
       "      <th>acquired</th>\n",
       "      <th>stim</th>\n",
       "      <th>channels</th>\n",
       "      <th>channel_stim</th>\n",
       "      <th>fov_object</th>\n",
       "      <th>channels_exposure</th>\n",
       "      <th>channel_stim_exposure</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stim_mid</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[miRFP, mCherry]</td>\n",
       "      <td>mCitrine</td>\n",
       "      <td>&lt;fov.FOV object at 0x00000206ECA062B0&gt;</td>\n",
       "      <td>[200, 100]</td>\n",
       "      <td>100.0</td>\n",
       "      <td>000_00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stim_mid</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[miRFP, mCherry]</td>\n",
       "      <td>mCitrine</td>\n",
       "      <td>&lt;fov.FOV object at 0x00000206ECA062B0&gt;</td>\n",
       "      <td>[200, 100]</td>\n",
       "      <td>100.0</td>\n",
       "      <td>000_00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fov timestep time time_experiment treatment acquired   stim  \\\n",
       "0   0        0    0             NaN  stim_mid    False  False   \n",
       "0   0        1    5             NaN  stim_mid    False  False   \n",
       "\n",
       "           channels channel_stim                              fov_object  \\\n",
       "0  [miRFP, mCherry]     mCitrine  <fov.FOV object at 0x00000206ECA062B0>   \n",
       "0  [miRFP, mCherry]     mCitrine  <fov.FOV object at 0x00000206ECA062B0>   \n",
       "\n",
       "  channels_exposure  channel_stim_exposure      fname  \n",
       "0        [200, 100]                  100.0  000_00000  \n",
       "0        [200, 100]                  100.0  000_00001  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acquire = pd.DataFrame(columns=['fov', 'timestep', 'time','time_experiment', 'treatment', 'acquired','stim', 'channels', 'channel_stim'])\n",
    "\n",
    "time_between_frames = 5 #time in seconds between frames\n",
    "stim_timesteps = [2,3]  # list of timesteps\n",
    "stim_timesteps= []  # list of timesteps\n",
    "\n",
    "timestep = range(2)  # 0-20\n",
    "treatments = ['stim_top', 'stim_mid',]  # list of treatments\n",
    "fovs:list[FOV] = fovs\n",
    "channels = [['miRFP','mCherry']]\n",
    "channels_exposure = [[200,100]]\n",
    "channel_stim = ['mCitrine']\n",
    "channel_stim_exposure = [100]\n",
    "\n",
    "ImgType.IMG_RAW\n",
    "\n",
    "# Loop over the FOVs and randomly assign one of the treatments to it\n",
    "treatments_shuffled = treatments.copy()\n",
    "random.shuffle(treatments_shuffled)\n",
    "for fov in fovs:\n",
    "    treatment = treatments_shuffled[fov.index % len(treatments_shuffled)]\n",
    "    for timestep in timestep:\n",
    "        new_row = { 'fov_object': fov,\n",
    "                    'fov':fov.index,\n",
    "                    'timestep': timestep,\n",
    "                    'time': timestep*time_between_frames,\n",
    "                    'treatment': treatment,\n",
    "                    'acquired': False,\n",
    "                    'stim': False,\n",
    "                    'channels': channels,\n",
    "                    'channels_exposure':channels_exposure,\n",
    "                    'channel_stim' : channel_stim,\n",
    "                    'channel_stim_exposure' : channel_stim_exposure,\n",
    "                    'fname' : f'{str(fov.index).zfill(3)}_{str(timestep).zfill(5)}',\n",
    "                    }\n",
    "        df_acquire = pd.concat([df_acquire, pd.DataFrame(new_row, index=[0])])\n",
    "\n",
    "for timestep in stim_timesteps:\n",
    "    df_acquire.loc[df_acquire['timestep'] == timestep, 'stim'] = True\n",
    "df_acquire = df_acquire.sort_values(by=['timestep', 'fov'])\n",
    "\n",
    "df_acquire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take an image at the current location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels to acquire: ['miRFP', 'mCherry']\n"
     ]
    }
   ],
   "source": [
    "print(f'Channels to acquire: {channels[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on virtual system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "from add_frame import ImageProcessingPipeline\n",
    "from segmentation import SegmentatorStardist\n",
    "from pymmcore_plus.mda import MDAEngine\n",
    "from stimulation import StimExtraParameters\n",
    "from controller import Analyzer\n",
    "\n",
    "segmentator = SegmentatorStardist('2D_versatile_fluo')\n",
    "stimulator = StimExtraParameters()\n",
    "tracker = TrackerTrackpy()\n",
    "pipeline = ImageProcessingPipeline(segmentator,stimulator,tracker)\n",
    "analyzer = Analyzer(pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2023-09-22 15:23:33,744 - pymmcore-plus - INFO - (_runner.py:216) MDA Started: GeneratorMDASequence()\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current timestep: 0\n",
      "Current timestep: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2023-09-22 15:23:33,750 - pymmcore-plus - INFO - (_runner.py:184) channel=Channel(config='miRFP') exposure=200.0 min_start_time=nan x_pos=16539.000246450305 y_pos=-12507.900186382234 metadata={'fov': <fov.FOV object at 0x00000206ECA062B0>, 'img_type': <ImgType.IMG_RAW: 1>, 'last_channel': False, 'timestep': 0, 'time': 0, 'time_experiment': nan, 'fname': '000_00000', 'stim': False, 'channels': ['miRFP', 'mCherry'], 'channel': 'miRFP'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No DMD mask found\n",
      "16539.000246450305 -12507.900186382234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2023-09-22 15:23:34,787 - pymmcore-plus - INFO - (_runner.py:184) channel=Channel(config='mCherry') exposure=100.0 min_start_time=nan x_pos=16539.000246450305 y_pos=-12507.900186382234 metadata={'fov': <fov.FOV object at 0x00000206ECA062B0>, 'img_type': <ImgType.IMG_RAW: 1>, 'last_channel': True, 'timestep': 0, 'time': 0, 'time_experiment': nan, 'fname': '000_00000', 'stim': False, 'channels': ['miRFP', 'mCherry'], 'channel': 'mCherry'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No DMD mask found\n",
      "16539.000246450305 -12507.900186382234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2023-09-22 15:23:37,071 - pymmcore-plus - INFO - (_runner.py:184) channel=Channel(config='miRFP') exposure=200.0 min_start_time=nan x_pos=16539.000246450305 y_pos=-12507.900186382234 metadata={'fov': <fov.FOV object at 0x00000206ECA062B0>, 'img_type': <ImgType.IMG_RAW: 1>, 'last_channel': False, 'timestep': 1, 'time': 5, 'time_experiment': nan, 'fname': '000_00001', 'stim': False, 'channels': ['miRFP', 'mCherry'], 'channel': 'miRFP'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No DMD mask found\n",
      "16539.000246450305 -12507.900186382234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2023-09-22 15:23:39,344 - pymmcore-plus - INFO - (_runner.py:184) channel=Channel(config='mCherry') exposure=100.0 min_start_time=nan x_pos=16539.000246450305 y_pos=-12507.900186382234 metadata={'fov': <fov.FOV object at 0x00000206ECA062B0>, 'img_type': <ImgType.IMG_RAW: 1>, 'last_channel': True, 'timestep': 1, 'time': 5, 'time_experiment': nan, 'fname': '000_00001', 'stim': False, 'channels': ['miRFP', 'mCherry'], 'channel': 'mCherry'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No DMD mask found\n",
      "16539.000246450305 -12507.900186382234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2023-09-22 15:23:41,592 - pymmcore-plus - INFO - (_runner.py:308) MDA Finished: GeneratorMDASequence()\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#mmc = CMMCorePlus()\n",
    "\n",
    "#mmc.loadSystemConfiguration()\n",
    "\n",
    "#setup camera\n",
    "#mmc.initializeDevice(\"Camera\");\n",
    "#mmc.setCameraDevice(\"Camera\");\n",
    "\n",
    "# Register the custom engine with the runner\n",
    "dmd = DMD(mmc, test_mode = False)\n",
    "mda_engine_dmd = MDAEngine_DMD(dmd)\n",
    "\n",
    "mmc.mda.set_engine(mda_engine_dmd)\n",
    "\n",
    "queue = Queue()\n",
    "controller = Controller(analyzer, mmc, queue)\n",
    "\n",
    "# Start the acquisition\n",
    "controller.run(df_acquire)\n",
    "#controller.run_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFP\n",
      "mCherry\n",
      "mCitrine\n",
      "miRFP\n"
     ]
    }
   ],
   "source": [
    "configs = mmc.getAvailableConfigs('Channel')\n",
    "for config in configs:\n",
    "    print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "assert np.array_equal(segmentator.segment(np.zeros((100,100))), np.zeros((100,100)))\n",
    "assert np.array_equal(stimulator.get_stim_mask(np.zeros((10,10)),FOV(0,0,'/tmp/',{},{'stim_property': 'top'})),np.ones((10,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luhin/miniforge3/envs/micro-llm/lib/python3.9/threading.py\", line 950, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/luhin/miniforge3/envs/micro-llm/lib/python3.9/threading.py\", line 888, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/luhin/sync/phd/code/rtm/add_frame.py\", line 41, in run\n",
      "    stim_mask = self.stimulator.get_stim_mask(segmented)\n",
      "TypeError: get_stim_mask() missing 1 required positional argument: 'fov'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from add_frame import store_img\n",
    "fov = FOV(pos=(0,0),index =i, path='/tmp/', metadata={'stim_property': 'top'},properties={},)\n",
    "metadata = {'fov':0,'img_type':ImgType.IMG_RAW,'fname':'test', 'fov_object':fov}\n",
    "store_img(np.ones((4,10,10)),metadata,'/tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Camera'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmc.snapImage()\n",
    "mmc.getImage()\n",
    "mmc.setExposure(100)\n",
    "mmc.getCameraDevice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on system with DMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No device with label \"\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m analyzer \u001b[39m=\u001b[39m Analyzer(pipeline)\n\u001b[1;32m     11\u001b[0m mmc \u001b[39m=\u001b[39m CMMCorePlus()\n\u001b[0;32m---> 12\u001b[0m dmd \u001b[39m=\u001b[39m DMD(mmc)\n\u001b[1;32m     14\u001b[0m mmc\u001b[39m.\u001b[39mloadSystemConfiguration()\n\u001b[1;32m     15\u001b[0m mmc\u001b[39m.\u001b[39mmda\u001b[39m.\u001b[39mset_engine(MDAEngine_DMD(mmc,dmd))\n",
      "File \u001b[0;32m~/sync/phd/code/rtm/dmd.py:25\u001b[0m, in \u001b[0;36mDMD.__init__\u001b[0;34m(self, mmc)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmmc \u001b[39m=\u001b[39m mmc\n\u001b[1;32m     24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmmc\u001b[39m.\u001b[39mgetSLMDevice()\n\u001b[0;32m---> 25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmmc\u001b[39m.\u001b[39;49mgetSLMHeight(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmmc\u001b[39m.\u001b[39mgetSLMWidth(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbppx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmmc\u001b[39m.\u001b[39mgetSLMBytesPerPixel(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No device with label \"\""
     ]
    }
   ],
   "source": [
    "from add_frame import ImageProcessingPipeline\n",
    "from segmentation import SegmentatorStardist\n",
    "\n",
    "segmentator = SegmentatorStardist('2D_versatile_fluo')\n",
    "stimulator = StimExtraParameters()\n",
    "pipeline = ImageProcessingPipeline(segmentator,stimulator)\n",
    "analyzer = Analyzer(pipeline)\n",
    "\n",
    "\n",
    "\n",
    "mmc = CMMCorePlus()\n",
    "dmd = DMD(mmc)\n",
    "\n",
    "mmc.loadSystemConfiguration()\n",
    "mmc.mda.set_engine(MDAEngine_DMD(mmc,dmd))\n",
    "\n",
    "# Apply the custom acquisition engine\n",
    "# Register the custom engine with the runner\n",
    "core = CMMCorePlus.instance()\n",
    "#core.mda.set_engine(MDAEngine_DMD(core))\n",
    "\n",
    "# create the Queue that will hold the MDAEvents\n",
    "queue = Queue()\n",
    "\n",
    "\n",
    "\n",
    "controller = Controller(analyzer, mmc , queue, dmd)\n",
    "# Start the acquisition\n",
    "controller.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-30 12:55:11.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpymmcore_plus.mda._runner\u001b[0m:\u001b[36m_prepare_to_run\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1mMDA Started: GeneratorMDASequence()\u001b[0m\n",
      "\u001b[32m2023-08-30 12:55:11.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpymmcore_plus.mda._runner\u001b[0m:\u001b[36m_run\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mchannel=Channel(config='Cy5') exposure=10.0 min_start_time=0.0 metadata={'fov': 0}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-30 12:55:12.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpymmcore_plus.mda._runner\u001b[0m:\u001b[36m_run\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mexposure=10.0 min_start_time=1.0 metadata={'fov': 1}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-30 12:55:13.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpymmcore_plus.mda._runner\u001b[0m:\u001b[36m_run\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mchannel=Channel(config='Cy5') exposure=10.0 min_start_time=2.0 metadata={'fov': 0}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-30 12:55:14.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpymmcore_plus.mda._runner\u001b[0m:\u001b[36m_run\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mexposure=10.0 min_start_time=3.0 metadata={'fov': 1}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-30 12:55:15.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpymmcore_plus.mda._runner\u001b[0m:\u001b[36m_run\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mchannel=Channel(config='Cy5') exposure=10.0 min_start_time=4.0 metadata={'fov': 0}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-30 12:55:16.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpymmcore_plus.mda._runner\u001b[0m:\u001b[36m_run\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mexposure=10.0 min_start_time=5.0 metadata={'fov': 1}\u001b[0m\n",
      "\u001b[32m2023-08-30 12:55:16.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpymmcore_plus.mda._runner\u001b[0m:\u001b[36m_finish_run\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mMDA Finished: GeneratorMDASequence()\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Simple simulator demonstrating event-driven acquisitions with pymmcore-plus.\"\"\"\n",
    "import random\n",
    "import time\n",
    "from queue import Queue\n",
    "\n",
    "import numpy as np\n",
    "from pymmcore_plus import CMMCorePlus\n",
    "from useq import MDAEvent, MDASequence\n",
    "\n",
    "\n",
    "class Analyzer:\n",
    "    \"\"\"Analyzes images and returns a dict of results.\"\"\"\n",
    "\n",
    "    def run(self, data) -> dict:\n",
    "        pass\n",
    "        # Fake analysis; randomly return a dict with a value of None 10% of the time\n",
    "        #if random.random() < 0.1:\n",
    "        #return {\"result\": \"STOP\"}\n",
    "\n",
    "       # else:\n",
    "        #return {\"result\": random.random()}\n",
    "\n",
    "\n",
    "class Controller:\n",
    "    STOP_EVENT = object()\n",
    "\n",
    "    def __init__(self, analyzer: Analyzer, mmc: CMMCorePlus, queue: Queue):\n",
    "        self._analyzer = analyzer  # analyzer of images\n",
    "        self._queue = queue  # queue of MDAEvents\n",
    "        self._results: dict = {}  # results of analysis\n",
    "\n",
    "        self._mmc = mmc\n",
    "        mmc.mda.events.frameReady.connect(self._on_frame_ready)\n",
    "\n",
    "    def _on_frame_ready(self, img: np.ndarray, event: MDAEvent) -> None:\n",
    "        # Analyze the image\n",
    "        #print(event)\n",
    "        self._results = self._analyzer.run(img)\n",
    "        print(event.metadata['fov'])\n",
    "\n",
    "    def run(self) -> None:\n",
    "        # convert the queue to an iterable\n",
    "        queue_sequence = iter(self._queue.get, self.STOP_EVENT)\n",
    "\n",
    "        # Start the acquisition (run_mda is non-blocking)\n",
    "        self._mmc.run_mda(queue_sequence)\n",
    "\n",
    "        # Queue the first image acquisition\n",
    "## Create MDASequence with a time delay of 1 second\n",
    "        \n",
    "        interval = 2\n",
    "        nb_fovs = 2\n",
    "        delay = interval/nb_fovs\n",
    "\n",
    "        mda_sequence_fov_0 = MDASequence(delay=10)\n",
    "        mda_sequence_fov_1 = MDASequence(exposure = 10)\n",
    "\n",
    "        channel = {'config': 'Cy5', 'exposure': 10}\n",
    "\n",
    "        for frame in range(3):\n",
    "            self._queue.put(MDAEvent(exposure=10,mda_sequence=mda_sequence_fov_0, min_start_time=frame *interval,metadata={'fov':0},channel=channel))\n",
    "            self._queue.put(MDAEvent(exposure=10,mda_sequence=mda_sequence_fov_1, min_start_time=frame *interval+delay,metadata={'fov':1}))\n",
    "\n",
    "\n",
    "       # self._queue.put(intitial_event)\n",
    "        self._queue.put(self.STOP_EVENT)\n",
    "\n",
    "\n",
    "# Setup the MM Core\n",
    "mmc = CMMCorePlus()\n",
    "mmc.loadSystemConfiguration()\n",
    "\n",
    "# create the Queue that will hold the MDAEvents\n",
    "q = Queue()\n",
    "\n",
    "# Setup the controller and analyzer\n",
    "analyzer = Analyzer()\n",
    "controller = Controller(analyzer, mmc, q)\n",
    "\n",
    "# Start the acquisition\n",
    "controller.run()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n"
     ]
    }
   ],
   "source": [
    "def normalize_mi_ma(x, mi, ma, clip=False, eps=1e-20, dtype=np.float32):\n",
    "    if dtype is not None:\n",
    "        x   = x.astype(dtype,copy=False)\n",
    "        mi  = dtype(mi) if np.isscalar(mi) else mi.astype(dtype,copy=False)\n",
    "        ma  = dtype(ma) if np.isscalar(ma) else ma.astype(dtype,copy=False)\n",
    "        eps = dtype(eps)\n",
    "\n",
    "def normalize(x, pmin=3, pmax=99.8, axis=None, clip=False, eps=1e-20, dtype=np.float32):\n",
    "    \"\"\"Percentile-based image normalization.\"\"\"\n",
    "\n",
    "    mi = np.percentile(x.flatten(),pmin)\n",
    "    ma = np.percentile(x.flatten(),pmax)\n",
    "    return normalize_mi_ma(x, mi, ma, clip=clip, eps=eps, dtype=dtype)\n",
    "\n",
    "normalize(np.ones((1000,1000)))\n",
    "print(np.ones((1000,1000)).flatten().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from queue import Queue\n",
    "\n",
    "import numpy as np\n",
    "from pymmcore_plus import CMMCorePlus\n",
    "from useq import MDAEvent, MDASequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_sequence_2 = MDASequence(exposure = 10)\n",
    "for event in mda_sequence_2:\n",
    "    intitial_event = event\n",
    "    print('here') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'napari_umanager'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnapari_umanager\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnapari_umanager\u001b[39;00m \u001b[39mimport\u001b[39;00m napari_manager\n\u001b[1;32m      3\u001b[0m napari_manager(viewer, mmc, q)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'napari_umanager'"
     ]
    }
   ],
   "source": [
    "import napari_umanager\n",
    "from napari_umanager import napari_manager\n",
    "napari_manager(viewer, mmc, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
