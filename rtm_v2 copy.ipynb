{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fov import FOV\n",
    "from queue import Queue\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "#from napari import Viewer\n",
    "import numpy as np\n",
    "from queue import Queue\n",
    "from pymmcore_plus import CMMCorePlus\n",
    "from useq import MDAEvent\n",
    "from useq._channel import Channel\n",
    "#from MDAEngine_DMD import MDAEngine_DMD\n",
    "import pandas as pd\n",
    "import random\n",
    "from utils import ImgType, MetadataDict\n",
    "#from stimulation import StimExtraParameters\n",
    "#from dmd import DMD\n",
    "from hardware import load_config\n",
    "import os\n",
    "from datetime import datetime\n",
    "import napari\n",
    "import pymmcore_widgets\n",
    "#import dmd\n",
    "\n",
    "import skimage\n",
    "\n",
    "\n",
    "# from tracking import TrackerTrackpy\n",
    "# from controller import Controller, Analyzer\n",
    "\n",
    "from utils import create_folders\n",
    "import numpy as np\n",
    "import pymmcore_plus\n",
    "\n",
    "import time\n",
    "\n",
    "from useq._mda_event import SLMImage\n",
    "\n",
    "\n",
    "mmc = pymmcore_plus.CMMCorePlus()\n",
    "mmc.loadSystemConfiguration(\"E:\\\\MicroManagerConfigs\\\\Ti2CicercoConfig_w_DMD_8_w_ttl.cfg\")\n",
    "#mmc.loadSystemConfiguration(\"C:\\\\Program Files\\\\Micro-Manager-2.0\\\\MMConfig_demo_SLM.cfg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmc.run.mda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari._qt.widgets.qt_viewer_dock_widget.QtViewerDockWidget at 0x18ce7f99a20>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "data_mda = pymmcore_widgets.MDAWidget()\n",
    "viewer.window.add_plugin_dock_widget(\"napari-micromanager\")\n",
    "viewer.window.add_dock_widget(data_mda, area=\"right\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a DF with all planned acquisitions and stimulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/18/24 13:08:11] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> MDA Started: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GeneratorMDASequence</span><span style=\"font-weight: bold\">()</span>                                     <a href=\"file://C:\\Users\\Niesen\\Documents\\lhinder\\code\\pymmcore-plus\\src\\pymmcore_plus\\mda\\_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Niesen\\Documents\\lhinder\\code\\pymmcore-plus\\src\\pymmcore_plus\\mda\\_runner.py#329\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/18/24 13:08:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m MDA Started: \u001b[1;35mGeneratorMDASequence\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                     \u001b]8;id=494919;file://C:\\Users\\Niesen\\Documents\\lhinder\\code\\pymmcore-plus\\src\\pymmcore_plus\\mda\\_runner.py\u001b\\\u001b[2m_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=193786;file://C:\\Users\\Niesen\\Documents\\lhinder\\code\\pymmcore-plus\\src\\pymmcore_plus\\mda\\_runner.py#329\u001b\\\u001b[2m329\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #808000; text-decoration-color: #808000\">slm_image</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SLMImage</span><span style=\"font-weight: bold\">()</span>                                                    <a href=\"file://C:\\Users\\Niesen\\Documents\\lhinder\\code\\pymmcore-plus\\src\\pymmcore_plus\\mda\\_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Niesen\\Documents\\lhinder\\code\\pymmcore-plus\\src\\pymmcore_plus\\mda\\_runner.py#290\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">290</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[33mslm_image\u001b[0m=\u001b[1;35mSLMImage\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                                    \u001b]8;id=217124;file://C:\\Users\\Niesen\\Documents\\lhinder\\code\\pymmcore-plus\\src\\pymmcore_plus\\mda\\_runner.py\u001b\\\u001b[2m_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=567384;file://C:\\Users\\Niesen\\Documents\\lhinder\\code\\pymmcore-plus\\src\\pymmcore_plus\\mda\\_runner.py#290\u001b\\\u001b[2m290\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> MDA Finished: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GeneratorMDASequence</span><span style=\"font-weight: bold\">()</span>                                    <a href=\"file://C:\\Users\\Niesen\\Documents\\lhinder\\code\\pymmcore-plus\\src\\pymmcore_plus\\mda\\_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Niesen\\Documents\\lhinder\\code\\pymmcore-plus\\src\\pymmcore_plus\\mda\\_runner.py#416\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">416</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m MDA Finished: \u001b[1;35mGeneratorMDASequence\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                    \u001b]8;id=681327;file://C:\\Users\\Niesen\\Documents\\lhinder\\code\\pymmcore-plus\\src\\pymmcore_plus\\mda\\_runner.py\u001b\\\u001b[2m_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=129778;file://C:\\Users\\Niesen\\Documents\\lhinder\\code\\pymmcore-plus\\src\\pymmcore_plus\\mda\\_runner.py#416\u001b\\\u001b[2m416\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slm_dev = mmc.getSLMDevice()\n",
    "slm_width = mmc.getSLMWidth(slm_dev)\n",
    "slm_height = mmc.getSLMHeight(slm_dev)\n",
    "\n",
    "#create a full on image to test the DMD \n",
    "#create a full on image to test the DMD \n",
    "img_255 = (np.ones((slm_height,slm_width))*255).astype(np.uint8)\n",
    "\n",
    "event_slm_on = MDAEvent(slm_image=SLMImage(data=img_255))\n",
    "mmc.mda.run([event_slm_on])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.draw import disk\n",
    "\n",
    "p0, p1, p2 = ([456,380],[304,760],[608,760])\n",
    "#p0, p1, p2 = ([30,38],[40,70],[60,76])\n",
    "\n",
    "radius = 5\n",
    "exposure = 30\n",
    "\n",
    "events = []\n",
    "for p in [p0,p1,p2]:\n",
    "    img_p = np.zeros((slm_height,slm_width)).astype(np.uint8)\n",
    "    rr, cc = disk((p[1],p[0]), radius)\n",
    "    img_p[rr,cc] = 255\n",
    "    event_p = MDAEvent(slm_image=SLMImage(data=img_p,device=slm_dev),exposure=exposure)\n",
    "    events.append(event_p)\n",
    "\n",
    "#disconnect previous callbacks\n",
    "mmc.mda.events.frameReady.disconnect()\n",
    "\n",
    "calibration_images = []\n",
    "\n",
    "@mmc.mda.events.frameReady.connect\n",
    "def new_frame(img: np.ndarray, event: MDAEvent):\n",
    "    calibration_images.append(img)\n",
    "\n",
    "mmc.mda.run(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_dmd_full = (np.ones((slm_height,slm_width))*255).astype(np.uint8)\n",
    "img_dmd_full_w_borders = img_dmd_full.copy()\n",
    "img_dmd_full_w_borders[0:10] = 0\n",
    "img_dmd_full_w_borders[:, 0:10] = 0\n",
    "img_dmd_full_w_borders[-10:] = 0\n",
    "img_dmd_full_w_borders[:, -10:] = 0\n",
    "\n",
    "valid_pixels = np.array(np.where(img_dmd_full_w_borders>0)).T\n",
    "\n",
    "src = []\n",
    "event_p = []\n",
    "events = []\n",
    "\n",
    "for i in range(10):\n",
    "    img_p = np.zeros((slm_height,slm_width)).astype(np.uint8)\n",
    "    p = random.choice(valid_pixels)\n",
    "    src.append((p[1],p[0]))\n",
    "    rr, cc = disk((p[0],p[1]), radius)\n",
    "    img_p[rr,cc] = 255\n",
    "    event_p = MDAEvent(slm_image=SLMImage(data=img_p,device=slm_dev),exposure=exposure)\n",
    "    events.append(event_p)\n",
    "\n",
    "#disconnect previous callbacks\n",
    "calibration_images = []\n",
    "mmc.mda.events.frameReady.disconnect()\n",
    "@mmc.mda.events.frameReady.connect\n",
    "def new_frame(img: np.ndarray, event: MDAEvent):\n",
    "    calibration_images.append(img)\n",
    "mmc.mda.run(events)\n",
    "\n",
    "calibration_images = np.array(calibration_images)\n",
    "dst = []\n",
    "for img in calibration_images:\n",
    "    #add gaussian filter\n",
    "    img = skimage.filters.gaussian(img, sigma=1)\n",
    "    max_x = np.argmax(img.max(axis=0))\n",
    "    max_y = np.argmax(img. max(axis=1))\n",
    "    dst.append((max_x,max_y))\n",
    "\n",
    "dst_napari = np.array(dst)[:,:]\n",
    "dst_napari[:,0] = np.array(dst)[:,1]\n",
    "dst_napari[:,1] = np.array(dst)[:,0]\n",
    "\n",
    "\n",
    "src = np.array(src)\n",
    "dst = np.array(dst)\n",
    "\n",
    "affine = skimage.transform.estimate_transform('affine', src, dst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_project = viewer.layers['Shapes'].data[0]*255\n",
    "img_project = img_project.astype(np.uint8)\n",
    "img_warp = skimage.transform.warp(img_project, affine, output_shape=(slm_height,slm_width), order=None, mode='constant', cval=0.0, clip=True, preserve_range=True)\n",
    "\n",
    "#display img_warp on the DMD\n",
    "img_warp = img_warp.astype(np.uint8)\n",
    "mmc.setSLMImage(slm_dev, img_warp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from useq._mda_event import SLMImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory C:\\teststim already exists\n",
      "Directory C:\\testraw already exists\n",
      "Directory C:\\testlabels already exists\n",
      "Directory C:\\teststim_mask already exists\n",
      "Directory C:\\testtracks already exists\n",
      "Directory C:\\testlabels_rings already exists\n",
      "Directory C:\\testparticles already exists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fov</th>\n",
       "      <th>timestep</th>\n",
       "      <th>time</th>\n",
       "      <th>time_experiment</th>\n",
       "      <th>treatment</th>\n",
       "      <th>acquired</th>\n",
       "      <th>stim</th>\n",
       "      <th>channels</th>\n",
       "      <th>channel_stim</th>\n",
       "      <th>fov_object</th>\n",
       "      <th>name</th>\n",
       "      <th>well_row</th>\n",
       "      <th>well_column</th>\n",
       "      <th>cell_line</th>\n",
       "      <th>channels_exposure</th>\n",
       "      <th>channel_stim_exposure</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[DAPI, Cy5]</td>\n",
       "      <td>FITC</td>\n",
       "      <td>&lt;fov.FOV object at 0x00000179B31F63D0&gt;</td>\n",
       "      <td>A1_0000</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>optoERK1</td>\n",
       "      <td>[200, 100]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>000_00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[DAPI, Cy5]</td>\n",
       "      <td>FITC</td>\n",
       "      <td>&lt;fov.FOV object at 0x00000179B2A4C210&gt;</td>\n",
       "      <td>A2_0008</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>optoERK2</td>\n",
       "      <td>[200, 100]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>001_00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[DAPI, Cy5]</td>\n",
       "      <td>FITC</td>\n",
       "      <td>&lt;fov.FOV object at 0x00000179B31F63D0&gt;</td>\n",
       "      <td>A1_0000</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>optoERK1</td>\n",
       "      <td>[200, 100]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>000_00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[DAPI, Cy5]</td>\n",
       "      <td>FITC</td>\n",
       "      <td>&lt;fov.FOV object at 0x00000179B2A4C210&gt;</td>\n",
       "      <td>A2_0008</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>optoERK2</td>\n",
       "      <td>[200, 100]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>001_00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[DAPI, Cy5]</td>\n",
       "      <td>FITC</td>\n",
       "      <td>&lt;fov.FOV object at 0x00000179B31F63D0&gt;</td>\n",
       "      <td>A1_0000</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>optoERK1</td>\n",
       "      <td>[200, 100]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>000_00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[DAPI, Cy5]</td>\n",
       "      <td>FITC</td>\n",
       "      <td>&lt;fov.FOV object at 0x00000179B2A4C210&gt;</td>\n",
       "      <td>A2_0008</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>optoERK2</td>\n",
       "      <td>[200, 100]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>001_00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[DAPI, Cy5]</td>\n",
       "      <td>FITC</td>\n",
       "      <td>&lt;fov.FOV object at 0x00000179B31F63D0&gt;</td>\n",
       "      <td>A1_0000</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>optoERK1</td>\n",
       "      <td>[200, 100]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>000_00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[DAPI, Cy5]</td>\n",
       "      <td>FITC</td>\n",
       "      <td>&lt;fov.FOV object at 0x00000179B2A4C210&gt;</td>\n",
       "      <td>A2_0008</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>optoERK2</td>\n",
       "      <td>[200, 100]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>001_00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[DAPI, Cy5]</td>\n",
       "      <td>FITC</td>\n",
       "      <td>&lt;fov.FOV object at 0x00000179B31F63D0&gt;</td>\n",
       "      <td>A1_0000</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>optoERK1</td>\n",
       "      <td>[200, 100]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>000_00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[DAPI, Cy5]</td>\n",
       "      <td>FITC</td>\n",
       "      <td>&lt;fov.FOV object at 0x00000179B2A4C210&gt;</td>\n",
       "      <td>A2_0008</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>optoERK2</td>\n",
       "      <td>[200, 100]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>001_00004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fov timestep time time_experiment treatment acquired   stim     channels  \\\n",
       "0   0        0    0             NaN      None    False  False  [DAPI, Cy5]   \n",
       "0   1        0    0             NaN      None    False  False  [DAPI, Cy5]   \n",
       "0   0        1    2             NaN      None    False  False  [DAPI, Cy5]   \n",
       "0   1        1    2             NaN      None    False  False  [DAPI, Cy5]   \n",
       "0   0        2    4             NaN      None    False   True  [DAPI, Cy5]   \n",
       "0   1        2    4             NaN      None    False   True  [DAPI, Cy5]   \n",
       "0   0        3    6             NaN      None    False  False  [DAPI, Cy5]   \n",
       "0   1        3    6             NaN      None    False  False  [DAPI, Cy5]   \n",
       "0   0        4    8             NaN      None    False  False  [DAPI, Cy5]   \n",
       "0   1        4    8             NaN      None    False  False  [DAPI, Cy5]   \n",
       "\n",
       "  channel_stim                              fov_object     name well_row  \\\n",
       "0         FITC  <fov.FOV object at 0x00000179B31F63D0>  A1_0000        A   \n",
       "0         FITC  <fov.FOV object at 0x00000179B2A4C210>  A2_0008        A   \n",
       "0         FITC  <fov.FOV object at 0x00000179B31F63D0>  A1_0000        A   \n",
       "0         FITC  <fov.FOV object at 0x00000179B2A4C210>  A2_0008        A   \n",
       "0         FITC  <fov.FOV object at 0x00000179B31F63D0>  A1_0000        A   \n",
       "0         FITC  <fov.FOV object at 0x00000179B2A4C210>  A2_0008        A   \n",
       "0         FITC  <fov.FOV object at 0x00000179B31F63D0>  A1_0000        A   \n",
       "0         FITC  <fov.FOV object at 0x00000179B2A4C210>  A2_0008        A   \n",
       "0         FITC  <fov.FOV object at 0x00000179B31F63D0>  A1_0000        A   \n",
       "0         FITC  <fov.FOV object at 0x00000179B2A4C210>  A2_0008        A   \n",
       "\n",
       "   well_column cell_line channels_exposure  channel_stim_exposure      fname  \n",
       "0          1.0  optoERK1        [200, 100]                   50.0  000_00000  \n",
       "0          2.0  optoERK2        [200, 100]                   50.0  001_00000  \n",
       "0          1.0  optoERK1        [200, 100]                   50.0  000_00001  \n",
       "0          2.0  optoERK2        [200, 100]                   50.0  001_00001  \n",
       "0          1.0  optoERK1        [200, 100]                   50.0  000_00002  \n",
       "0          2.0  optoERK2        [200, 100]                   50.0  001_00002  \n",
       "0          1.0  optoERK1        [200, 100]                   50.0  000_00003  \n",
       "0          2.0  optoERK2        [200, 100]                   50.0  001_00003  \n",
       "0          1.0  optoERK1        [200, 100]                   50.0  000_00004  \n",
       "0          2.0  optoERK2        [200, 100]                   50.0  001_00004  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acquire = pd.DataFrame(columns=['fov', 'timestep', 'time','time_experiment', 'treatment', 'acquired','stim', 'channels', 'channel_stim'])\n",
    "\n",
    "path = \"C:\\\\test\\\\\"\n",
    "create_folders(path,['stim','raw','labels','stim_mask','tracks','labels_rings','particles'])\n",
    "\n",
    "time_between_frames = 2 #time in seconds between frames\n",
    "stim_timesteps = [2]  # list of timesteps\n",
    "\n",
    "timesteps = range(5)  # 0-20\n",
    "treatments = None\n",
    "channels = [['DAPI','Cy5']]\n",
    "channels_exposure = [[200,100]]\n",
    "channel_stim = ['FITC']\n",
    "channel_stim_exposures = {\"A\": 50, \"B\": 100, \"C\": 150, \"D\": 250}\n",
    "# channel_stim_exposure = [100]\n",
    "\n",
    "fovs:list[FOV] = []\n",
    "\n",
    "data_mda_fovs = data_mda.value()\n",
    "\n",
    "for i, row in enumerate(data_mda_fovs.stage_positions):\n",
    "    fov = FOV(pos=(row.x, row.y),\n",
    "              index=i,\n",
    "              name=row.name,\n",
    "              path=path,\n",
    "              metadata={},\n",
    "              properties={'stim_property': 'global'},\n",
    "              )\n",
    "    fovs.append(fov)\n",
    "\n",
    "\n",
    "for fov in fovs:\n",
    "    well_column = int(fov.name.split('_')[0][1:])\n",
    "    well_row = fov.name.split('_')[0][0]\n",
    "    treatment = None\n",
    "    cell_lines = [\"optoFGFR1\", \"optoERK1\", \"optoERK2\", \"optoTrkA1\"]\n",
    "    cell_line = cell_lines[well_column]\n",
    "    \n",
    "    for timestep in timesteps:\n",
    "        new_row = { 'fov_object': fov,\n",
    "                    'fov':fov.index,\n",
    "                    'name':fov.name,\n",
    "                    'well_row': well_row,\n",
    "                    'well_column': int(well_column),\n",
    "                    'cell_line': cell_line,\n",
    "                    'timestep': timestep,\n",
    "                    'time': timestep*time_between_frames,\n",
    "                    'treatment': treatment,\n",
    "                    'acquired': False,\n",
    "                    'stim': timestep in stim_timesteps,\n",
    "                    'channels': channels,\n",
    "                    'channels_exposure':channels_exposure,\n",
    "                    'channel_stim' : channel_stim,\n",
    "                    'channel_stim_exposure' : channel_stim_exposures[well_row],\n",
    "                    'fname' : f'{str(fov.index).zfill(3)}_{str(timestep).zfill(5)}',\n",
    "                    }\n",
    "        df_acquire = pd.concat([df_acquire, pd.DataFrame(new_row, index=[0])])\n",
    "\n",
    "\n",
    "df_acquire = df_acquire.sort_values(by=['timestep', 'fov'])\n",
    "\n",
    "df_acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot start an MDA while the previous MDA is still running.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 109\u001b[0m\n\u001b[0;32m    106\u001b[0m controller \u001b[38;5;241m=\u001b[39m Controller(mmc , queue)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Start the acquisitiondd\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m controller\u001b[38;5;241m.\u001b[39mrun(df_acquire\u001b[38;5;241m=\u001b[39mdf_acquire)\n",
      "Cell \u001b[1;32mIn[142], line 35\u001b[0m, in \u001b[0;36mController.run\u001b[1;34m(self, df_acquire)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#convert queue to an iterable\u001b[39;00m\n\u001b[0;32m     34\u001b[0m queue_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39mget, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSTOP_EVENT)\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mmc\u001b[38;5;241m.\u001b[39mrun_mda(queue_sequence)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m timestep \u001b[38;5;129;01min\u001b[39;00m df_acquire[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestep\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent timestep: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\mambaforge\\envs\\pymmcore\\Lib\\site-packages\\pymmcore_plus\\core\\_mmcore_plus.py:1453\u001b[0m, in \u001b[0;36mCMMCorePlus.run_mda\u001b[1;34m(self, events, output, block)\u001b[0m\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run a sequence of [useq.MDAEvent][] on a new thread.\u001b[39;00m\n\u001b[0;32m   1419\u001b[0m \n\u001b[0;32m   1420\u001b[0m \u001b[38;5;124;03m:sparkles: *This method is new in `CMMCorePlus`.*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1450\u001b[0m \u001b[38;5;124;03m    done, or `thread.is_alive()` to check if the sequence is complete.\u001b[39;00m\n\u001b[0;32m   1451\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmda\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m-> 1453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot start an MDA while the previous MDA is still running.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1455\u001b[0m     )\n\u001b[0;32m   1456\u001b[0m th \u001b[38;5;241m=\u001b[39m Thread(target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmda\u001b[38;5;241m.\u001b[39mrun, args\u001b[38;5;241m=\u001b[39m(events,), kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: output})\n\u001b[0;32m   1457\u001b[0m th\u001b[38;5;241m.\u001b[39mstart()\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot start an MDA while the previous MDA is still running."
     ]
    }
   ],
   "source": [
    "import useq\n",
    "import queue\n",
    "class Controller:\n",
    "    STOP_EVENT = object()\n",
    "\n",
    "    def __init__(self, mmc: CMMCorePlus, queue: Queue, dmd: DMD=None):\n",
    "        self._queue = queue  # queue of MDAEvents\n",
    "        self._results: dict = {}  # results of analysis\n",
    "        self._mmc = mmc\n",
    "        self._frame_buffer = [] # buffer to hold the frames until one sequence is complete\n",
    "        self._dmd = dmd\n",
    "        mmc.mda.events.frameReady.connect(self._on_frame_ready)\n",
    "\n",
    "\n",
    "    def _on_frame_ready(self, img: np.ndarray, event: MDAEvent) -> None:\n",
    "        # Analyze the image\n",
    "        self._frame_buffer.append(img)\n",
    "        \n",
    "        # check if it's the last acquisition for this MDAsequence\n",
    "        if event.metadata['last_channel']:\n",
    "            frame_complete = np.stack(self._frame_buffer, axis=-1)\n",
    "            #move new axis to the first position\n",
    "            frame_complete = np.moveaxis(frame_complete, -1, 0)\n",
    "\n",
    "            self._frame_buffer = []\n",
    "            #self._results = self._analyzer.run(frame_complete,event.metadata)\n",
    "            self._results = self._analyzer.run(frame_complete,event) \n",
    "        \n",
    "\n",
    "    def run(self, df_acquire:pd.DataFrame):\n",
    "        timestep = 0\n",
    "\n",
    "        #convert queue to an iterable\n",
    "        queue_sequence = iter(self._queue.get, self.STOP_EVENT)\n",
    "        self._mmc.run_mda(queue_sequence)\n",
    "\n",
    "        for timestep in df_acquire['timestep'].unique():\n",
    "            print(f\"Current timestep: {timestep}\")\n",
    "        # extract the lines with the current timestep from the DF\n",
    "            current_timestep_df = df_acquire[df_acquire['timestep'] == timestep]\n",
    "\n",
    "            for index, row in current_timestep_df.iterrows():\n",
    "                fov : FOV = row['fov_object']\n",
    "                timestep = row['timestep']\n",
    "                stim = row['stim']\n",
    "                channels = row['channels']\n",
    "                channels_exposure = row['channels_exposure']\n",
    "                channel_stim = row['channel_stim']\n",
    "                channel_stim_exposure = row['channel_stim_exposure']\n",
    "\n",
    "                metadata_dict = dict(row)\n",
    "                metadata_dict['img_type']= ImgType.IMG_RAW\n",
    "                metadata_dict['last_channel']= channels[-1]\n",
    "                                            \n",
    "                if self._dmd != None:\n",
    "                    metadata_dict['stim_mask'] = self._dmd.sample_mask_on\n",
    "                    \n",
    "                ### Capture the raw image without DMD illumination\n",
    "                for i,channel in enumerate(channels):\n",
    "                    last_channel:bool = i == len(channels)-1\n",
    "                    metadata_dict['last_channel'] = last_channel\n",
    "                    metadata_dict['channel'] = channel\n",
    "\n",
    "                    acquisition_event = useq.MDAEvent(\n",
    "                            channel = channel, # the channel presets we want to acquire\n",
    "                            metadata = metadata_dict, # (custom) metadata that is attatched to the event/image\n",
    "                            x_pos = fov.pos[0], # only one pos for all channels\n",
    "                            y_pos = fov.pos[1],\n",
    "                            sequence = fov.mda_sequence,\n",
    "                            min_start_time = row['time'],\n",
    "                            exposure=channels_exposure[i]\n",
    "                        )\n",
    "                    \n",
    "                    #add the event to the acquisition queue\n",
    "                    self._queue.put(acquisition_event)\n",
    "\n",
    "                if stim:\n",
    "                    ### Stimulate using the DMD if stim is True\n",
    "                    stim_mask = fov.stim_mask_queue.get(timeout=10) #wait max 10s for mask\n",
    "                    #affine transform the mask to the DMD coordinates\n",
    "                    if self._dmd != None:\n",
    "                        stim_mask = self._dmd.affine_transform(stim_mask)\n",
    "\n",
    "                    ### expose the image\n",
    "                    metadata_dict['img_type'] = ImgType.IMG_STIM #change the img_type and channels, rest stays the same\n",
    "                    metadata_dict['last_channel'] = True\n",
    "                    metadata_dict['channel'] = channel_stim      \n",
    "\n",
    "                    stimulation_event = useq.MDAEvent(\n",
    "                        channel = channel_stim, # the channel presets we want to acquire\n",
    "                        metadata = metadata_dict, # (custom) metadata that is attatched to the event/image\n",
    "                        x_pos = fov.pos[0], # only one pos for all channels\n",
    "                        y_pos = fov.pos[1],\n",
    "                        exposure = channel_stim_exposure\n",
    "                    )\n",
    "                    self._queue.put(stimulation_event)   \n",
    "\n",
    "        # Reached end of acquisition DF\n",
    "        for fov in df_acquire['fov_object'].unique():\n",
    "            fov.tracks = fov.tracks_queue.get(timeout=10) #wait max 10s for tracks\n",
    "\n",
    "        # Put the stop event in the queue\n",
    "        self._queue.put(self.STOP_EVENT)\n",
    "\n",
    "queue = Queue()\n",
    "controller = Controller(mmc , queue)\n",
    "\n",
    "controller.run(df_acquire=df_acquire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<object at 0x179b2e36780>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controller.STOP_EVENT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on system with DMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.73416961e-01,  9.76489146e-01,  2.46601067e+01],\n",
       "       [ 7.43596485e+00,  1.28445880e-01, -2.69683317e+03]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from add_frame import ImageProcessingPipeline\n",
    "from segmentation import SegmentatorStardist\n",
    "from controller import Controller, Analyzer\n",
    "from tracking import TrackerNoTracking\n",
    "\n",
    "segmentator = SegmentatorStardist('2D_versatile_fluo')\n",
    "stimulator = StimExtraParameters()\n",
    "#tracker = TrackerTrackpy(search_range=10,memory=3,adaptive_stop=1,adaptive_step=0.8)\n",
    "tracker = TrackerNoTracking()\n",
    "\n",
    "pipeline = ImageProcessingPipeline(segmentator,stimulator,tracker)\n",
    "analyzer = Analyzer(pipeline)\n",
    "\n",
    "dmd = DMD(mmc)\n",
    "\n",
    "dmd.calibrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2023-10-24 16:57:30,725 - pymmcore-plus - INFO - (_runner.py:216) MDA Started: GeneratorMDASequence()\u001b[0m\n",
      "\u001b[38;20m2023-10-24 16:57:30,729 - pymmcore-plus - INFO - (_runner.py:184) channel=Channel(config='miRFP') exposure=200.0 min_start_time=0.0 x_pos=12.6 y_pos=2484.5 metadata={'fov': 0, 'timestep': 0, 'time': 0, 'time_experiment': nan, 'treatment': 'stim_mid', 'acquired': False, 'stim': False, 'channels': ['miRFP', 'mCherry'], 'channel_stim': 'mCitrine', 'fov_object': <fov.FOV object at 0x000002B4D4F224F0>, 'name': 'Pos000', 'channels_exposure': [200, 100], 'channel_stim_exposure': 100.0, 'fname': '000_00000', 'offset_x': 0.0, 'offset_y': 10.0, 'radius': 10.0, 'img_type': <ImgType.IMG_RAW: 1>, 'last_channel': False, 'stim_mask': array([[255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       ...,\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8), 'channel': 'miRFP'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current timestep: 0\n",
      "Current timestep: 1\n",
      "reading queue: Pos000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2023-10-24 16:57:31,764 - pymmcore-plus - INFO - (_runner.py:184) channel=Channel(config='mCherry') exposure=100.0 min_start_time=0.0 x_pos=12.6 y_pos=2484.5 metadata={'fov': 0, 'timestep': 0, 'time': 0, 'time_experiment': nan, 'treatment': 'stim_mid', 'acquired': False, 'stim': False, 'channels': ['miRFP', 'mCherry'], 'channel_stim': 'mCitrine', 'fov_object': <fov.FOV object at 0x000002B4D4F224F0>, 'name': 'Pos000', 'channels_exposure': [200, 100], 'channel_stim_exposure': 100.0, 'fname': '000_00000', 'offset_x': 0.0, 'offset_y': 10.0, 'radius': 10.0, 'img_type': <ImgType.IMG_RAW: 1>, 'last_channel': True, 'stim_mask': array([[255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       ...,\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8), 'channel': 'mCherry'}\u001b[0m\n"
     ]
    },
    {
     "ename": "Empty",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\micromanager\\Documents\\lhinder\\code\\rtm-pymmcore\\rtm.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/micromanager/Documents/lhinder/code/rtm-pymmcore/rtm.ipynb#Y104sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m controller \u001b[39m=\u001b[39m Controller(analyzer, mmc , queue, dmd)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/micromanager/Documents/lhinder/code/rtm-pymmcore/rtm.ipynb#Y104sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Start the acquisitiondd\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/micromanager/Documents/lhinder/code/rtm-pymmcore/rtm.ipynb#Y104sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m controller\u001b[39m.\u001b[39;49mrun(df_acquire\u001b[39m=\u001b[39;49mdf_acquire)\n",
      "File \u001b[1;32mc:\\Users\\micromanager\\Documents\\lhinder\\code\\rtm-pymmcore\\controller.py:101\u001b[0m, in \u001b[0;36mController.run\u001b[1;34m(self, df_acquire)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m timestep \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    100\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mreading queue: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m fov\u001b[39m.\u001b[39mname)\n\u001b[1;32m--> 101\u001b[0m     fov\u001b[39m.\u001b[39mtracks \u001b[39m=\u001b[39m fov\u001b[39m.\u001b[39;49mtracks_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m) \u001b[39m#wait max 10s for tracks\u001b[39;00m\n\u001b[0;32m    103\u001b[0m metadata_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(row)\n\u001b[0;32m    104\u001b[0m metadata_dict[\u001b[39m'\u001b[39m\u001b[39mimg_type\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m ImgType\u001b[39m.\u001b[39mIMG_RAW\n",
      "File \u001b[1;32mc:\\Users\\micromanager\\anaconda3\\envs\\rtm-pymmcore-lhinder\\lib\\queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    177\u001b[0m         remaining \u001b[39m=\u001b[39m endtime \u001b[39m-\u001b[39m time()\n\u001b[0;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m--> 179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    180\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_empty\u001b[39m.\u001b[39mwait(remaining)\n\u001b[0;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n",
      "\u001b[1;31mEmpty\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [mean_intensity_C0_nuc, mean_intensity_C1_nuc, x, y, mean_intensity_C0_ring, mean_intensity_C1_ring, label, ratio_ERK, particle, frame, stim, time]\n",
      "Index: []\n",
      "putting tracks into queue, fov: Pos000\n",
      "Empty DataFrame\n",
      "Columns: [mean_intensity_C0_nuc, mean_intensity_C1_nuc, x, y, mean_intensity_C0_ring, mean_intensity_C1_ring, label, ratio_ERK, particle, frame, stim, time]\n",
      "Index: []\n",
      "putting tracks into queue, fov: Pos000\n",
      "Empty DataFrame\n",
      "Columns: [mean_intensity_C0_nuc, mean_intensity_C1_nuc, x, y, mean_intensity_C0_ring, mean_intensity_C1_ring, label, ratio_ERK, particle, frame, stim, time]\n",
      "Index: []\n",
      "putting tracks into queue, fov: Pos000\n"
     ]
    }
   ],
   "source": [
    "mmc.mda.set_engine(MDAEngine_DMD(dmd))\n",
    "\n",
    "# Apply the custom acquisition engine\n",
    "# Register the custom engine with the runner\n",
    "#core.mda.set_engine(MDAEngine_DMD(core))\n",
    "\n",
    "# create the Queue that will hold the MDAEvents\n",
    "queue = Queue()\n",
    "controller = Controller(analyzer, mmc , queue, dmd)\n",
    "\n",
    "# Start the acquisitiondd\n",
    "controller.run(df_acquire=df_acquire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue.put(controller.STOP_EVENT)\n",
    "mmc.mda.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmc.mda.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmc.unloadAllDevices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "from add_frame import ImageProcessingPipeline\n",
    "from segmentation import SegmentatorStardist\n",
    "from pymmcore_plus.mda import MDAEngine\n",
    "from stimulation import StimExtraParameters, StimCircle\n",
    "from controller import Analyzer\n",
    "\n",
    "segmentator = SegmentatorStardist('2D_versatile_fluo')\n",
    "stimulator = StimExtraParameters()\n",
    "stimulator = StimCircle()\n",
    "tracker = TrackerTrackpy()\n",
    "pipeline = ImageProcessingPipeline(segmentator,stimulator,tracker)\n",
    "analyzer = Analyzer(pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import zarr\n",
    "import glob\n",
    "from skimage.io import imread\n",
    "from glob import glob\n",
    "import dask.array as da\n",
    "from dask import delayed\n",
    "import os\n",
    "import numpy as np\n",
    "from magicgui import magicgui\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def tiff_to_lazy_da(path,folder,fov, zfill = 2):\n",
    "    '''Read in all tiff files form the same FOV in a folder and load them lazily with dask. '''\n",
    "    file_name_pattern = str(fov).zfill(zfill)+\"_*.tiff\"\n",
    "    filenames = sorted(glob(path + os.path.join(str(folder),file_name_pattern)))\n",
    "    # read the first file to get the shape and dtype\n",
    "    # ASSUMES THAT ALL FILES SHARE THE SAME SHAPE and TYPE\n",
    "\n",
    "    sample = imread(filenames[0])\n",
    "    \n",
    "    lazy_imread = delayed(imread)  # lazy reader\n",
    "    lazy_arrays = [lazy_imread(fn) for fn in filenames]\n",
    "    dask_arrays = [\n",
    "        da.from_delayed(delayed_reader, shape=sample.shape, dtype=sample.dtype)\n",
    "        for delayed_reader in lazy_arrays\n",
    "    ]\n",
    "    # Stack into one large dask.array\n",
    "    stack = da.stack(dask_arrays, axis=0)\n",
    "    stack = np.squeeze(stack)\n",
    "    return stack\n",
    "\n",
    "project_path = '/Volumes/imaging.data/lhinder/data/rtm_mm_data/exp_352/'\n",
    "stack_raw = tiff_to_lazy_da(project_path, \"raw\", 0,zfill=2)\n",
    "stack_stim = tiff_to_lazy_da(project_path, \"stim\", 0,zfill=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stack_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\micromanager\\Documents\\lhinder\\code\\rtm-pymmcore\\rtm.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/micromanager/Documents/lhinder/code/rtm-pymmcore/rtm.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m### RUN THIS IF YOU WANT TO TEST THE ACQUISITION WITHOUT ACTUAL HARDWARE\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/micromanager/Documents/lhinder/code/rtm-pymmcore/rtm.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m analyzer \u001b[39m=\u001b[39m Analyzer(pipeline)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/micromanager/Documents/lhinder/code/rtm-pymmcore/rtm.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m controller \u001b[39m=\u001b[39m Controller(analyzer, mmc, queue,stack_raw\u001b[39m=\u001b[39mstack_raw,stack_stim\u001b[39m=\u001b[39mstack_stim)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/micromanager/Documents/lhinder/code/rtm-pymmcore/rtm.ipynb#X22sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Start the acquisition\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/micromanager/Documents/lhinder/code/rtm-pymmcore/rtm.ipynb#X22sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m controller\u001b[39m.\u001b[39mrun(df_acquire)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stack_raw' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from controller_simulation import Controller, Analyzer\n",
    "from dmd import DMD\n",
    "\n",
    "dmd = DMD(mmc, test_mode = True)\n",
    "mda_engine_dmd = MDAEngine_DMD(dmd)\n",
    "\n",
    "mmc.mda.set_engine(mda_engine_dmd)\n",
    "\n",
    "queue = Queue()\n",
    "\n",
    "### RUN THIS IF YOU WANT TO TEST THE ACQUISITION WITHOUT ACTUAL HARDWARE\n",
    "analyzer = Analyzer(pipeline)\n",
    "controller = Controller(analyzer, mmc, queue,stack_raw=stack_raw,stack_stim=stack_stim)\n",
    "\n",
    "\n",
    "# Start the acquisition\n",
    "controller.run(df_acquire)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Core',)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmc.getLoadedDevices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n"
     ]
    }
   ],
   "source": [
    "def normalize_mi_ma(x, mi, ma, clip=False, eps=1e-20, dtype=np.float32):\n",
    "    if dtype is not None:\n",
    "        x   = x.astype(dtype,copy=False)\n",
    "        mi  = dtype(mi) if np.isscalar(mi) else mi.astype(dtype,copy=False)\n",
    "        ma  = dtype(ma) if np.isscalar(ma) else ma.astype(dtype,copy=False)\n",
    "        eps = dtype(eps)\n",
    "\n",
    "def normalize(x, pmin=3, pmax=99.8, axis=None, clip=False, eps=1e-20, dtype=np.float32):\n",
    "    \"\"\"Percentile-based image normalization.\"\"\"\n",
    "\n",
    "    mi = np.percentile(x.flatten(),pmin)\n",
    "    ma = np.percentile(x.flatten(),pmax)\n",
    "    return normalize_mi_ma(x, mi, ma, clip=clip, eps=eps, dtype=dtype)\n",
    "\n",
    "normalize(np.ones((1000,1000)))\n",
    "print(np.ones((1000,1000)).flatten().shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymmcore-lucien",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
